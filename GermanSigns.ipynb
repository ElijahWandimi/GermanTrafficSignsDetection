{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING THE NECCESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA LOADING AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('Train.csv')\n",
    "test_csv = pd.read_csv('Test.csv')\n",
    "meta_csv = pd.read_csv('Meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId  \\\n",
       "0     27      26       5       5      22      20       20   \n",
       "1     28      27       5       6      23      22       20   \n",
       "2     29      26       6       5      24      21       20   \n",
       "3     28      27       5       6      23      22       20   \n",
       "4     28      26       5       5      23      21       20   \n",
       "\n",
       "                             Path  \n",
       "0  Train/20/00020_00000_00000.png  \n",
       "1  Train/20/00020_00000_00001.png  \n",
       "2  Train/20/00020_00000_00002.png  \n",
       "3  Train/20/00020_00000_00003.png  \n",
       "4  Train/20/00020_00000_00004.png  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROPROCESSING THE DATA AND CREATING IMAGE DATA GENERATORS FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function splits the training images into training and validation images\n",
    "def split_data(data_path, train_data_path, val_data_path, split_size = 0.1):\n",
    "\n",
    "    folders = os.listdir(data_path)\n",
    "\n",
    "    for folder in folders:\n",
    "        full_path = os.path.join(data_path, folder)\n",
    "        images_path = glob.glob(os.path.join(full_path, '*.png'))\n",
    "\n",
    "        x_train, x_val = train_test_split(images_path, test_size=split_size)\n",
    "\n",
    "        # train images\n",
    "        for x in x_train:\n",
    "            # basename = os.path.basename(x)\n",
    "            folder_path = os.path.join(train_data_path, folder)\n",
    "\n",
    "            if not os.path.isdir(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "\n",
    "            shutil.copy(x, folder_path)\n",
    "\n",
    "            # validation images\n",
    "        for x in x_val:\n",
    "            folder_path = os.path.join(val_data_path, folder)\n",
    "\n",
    "            if not os.path.isdir(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "\n",
    "            shutil.copy(x, folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/elijah/GermanTrafficSignsDetection/Train/'\n",
    "train_data_path = '/home/elijah/GermanTrafficSignsDetection/training_data/train/'\n",
    "val_data_path = '/home/elijah/GermanTrafficSignsDetection/training_data/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(data_path, train_data_path, val_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to orderly put test images into their respective class labels\n",
    "def order_test(image_path, csv_path):\n",
    "    testset = {}\n",
    "\n",
    "    try:\n",
    "        with open(csv_path, 'r') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "            for i, row in enumerate(reader):\n",
    "                if i==0:\n",
    "                    continue\n",
    "                image_name = row[-1].replace('Test/', '')\n",
    "                label = row[-2]\n",
    "                path_to_folder = os.path.join(image_path, label)\n",
    "\n",
    "                if not os.path.isdir(path_to_folder):\n",
    "                    os.makedirs(path_to_folder)\n",
    "                image_full_path = os.path.join(image_path, image_name)\n",
    "                shutil.move(image_full_path, path_to_folder)\n",
    "    except:\n",
    "        print('[INFO] : Error reading csv file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_test(image_path='/home/elijah/GermanTrafficSignsDetection/Test/',\n",
    "            csv_path='/home/elijah/GermanTrafficSignsDetection/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data generators to create labelled images and put them in batches for training the CNN\n",
    "def create_generators(batch_size, traindata, valdata, testdata):\n",
    "    preprocessor = ImageDataGenerator(\n",
    "        rescale=1/255,\n",
    "    )\n",
    "    train_generator = preprocessor.flow_from_directory(\n",
    "        traindata,\n",
    "        class_mode='categorical',\n",
    "        target_size=(60,60),\n",
    "        color_mode='rgb',\n",
    "        shuffle=True,\n",
    "        batch_size= batch_size\n",
    "    )\n",
    "\n",
    "    validation_generator = preprocessor.flow_from_directory(\n",
    "        valdata,\n",
    "        class_mode='categorical',\n",
    "        target_size=(60,60),\n",
    "        color_mode='rgb',\n",
    "        shuffle=False,\n",
    "        batch_size= batch_size\n",
    "    )\n",
    "\n",
    "    test_generator = preprocessor.flow_from_directory(\n",
    "        testdata,\n",
    "        class_mode='categorical',\n",
    "        target_size=(60,60),\n",
    "        color_mode='rgb',\n",
    "        shuffle=False,\n",
    "        batch_size= batch_size\n",
    "    )\n",
    "\n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37745 images belonging to 43 classes.\n",
      "Found 6301 images belonging to 43 classes.\n",
      "Found 12630 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "traindata = '/home/elijah/GermanTrafficSignsDetection/training_data/train/'\n",
    "valdata = '/home/elijah/GermanTrafficSignsDetection/training_data/validation/'\n",
    "testdata = '/home/elijah/GermanTrafficSignsDetection/Test/'\n",
    "batch_size = 50\n",
    "\n",
    "train_generator, validation_generator, test_generator = create_generators(\n",
    "    batch_size,\n",
    "    traindata,\n",
    "    valdata,\n",
    "    testdata\n",
    ")\n",
    "num_classes = train_generator.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING AND EVALUATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import StreetSignDetector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 60, 60, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 58, 58, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 29, 29, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 27, 27, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 13, 13, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 43)                22059     \n",
      "=================================================================\n",
      "Total params: 1,839,531\n",
      "Trainable params: 1,837,611\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = StreetSignDetector(num_classes=num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy',]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './Models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_saver = ModelCheckpoint(\n",
    "    model_path,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    save_freq='epoch',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "755/755 [==============================] - 695s 921ms/step - loss: 0.0287 - accuracy: 0.9918 - val_loss: 0.1069 - val_accuracy: 0.9805\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.98048, saving model to ./Models\n",
      "INFO:tensorflow:Assets written to: ./Models/assets\n",
      "Epoch 2/3\n",
      "755/755 [==============================] - 692s 916ms/step - loss: 0.0239 - accuracy: 0.9935 - val_loss: 0.0137 - val_accuracy: 0.9956\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.98048 to 0.99556, saving model to ./Models\n",
      "INFO:tensorflow:Assets written to: ./Models/assets\n",
      "Epoch 3/3\n",
      "755/755 [==============================] - 713s 945ms/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.1159 - val_accuracy: 0.9678\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.99556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd3900b4130>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=3,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[ckpt_saver, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 24s 191ms/step - loss: 0.1159 - accuracy: 0.9678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11592686176300049, 0.9677829146385193]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253/253 [==============================] - 63s 249ms/step - loss: 0.5277 - accuracy: 0.9131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5276893973350525, 0.9130641222000122]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb5e4bc5782b3abb0fcf6e9a69bb660914a42eab5af676c0b66f01cc5072dc2d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('signsenv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
